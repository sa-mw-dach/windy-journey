apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "5"
    enable-route: "true"
    opendatahub.io/accelerator-name: ""
    opendatahub.io/apiProtocol: REST
    opendatahub.io/recommended-accelerators: '["nvidia.com/gpu"]'
    opendatahub.io/template-display-name: OpenVINO Model Server
    opendatahub.io/template-name: ovms
    openshift.io/display-name: wjvi
  labels:
    opendatahub.io/dashboard: "true"
  name: wjvi
spec:
  builtInAdapter:
    env:
    - name: OVMS_FORCE_TARGET_DEVICE
      value: AUTO
    memBufferBytes: 134217728
    modelLoadingTimeoutMillis: 90000
    runtimeManagementPort: 8888
    serverType: ovms
  containers:
  - args:
    - --port=8001
    - --rest_port=8888
    - --config_path=/models/model_config_list.json
    - --file_system_poll_wait_seconds=0
    - --grpc_bind_address=127.0.0.1
    - --rest_bind_address=127.0.0.1
    image: quay.io/modh/openvino_model_server@sha256:5d04d405526ea4ce5b807d0cd199ccf7f71bab1228907c091e975efa770a4908
    name: ovms
    resources:
      limits:
        cpu: "2"
        memory: 8Gi
      requests:
        cpu: "1"
        memory: 4Gi
    volumeMounts:
    - mountPath: /dev/shm
      name: shm
  grpcDataEndpoint: port:8001
  grpcEndpoint: port:8085
  multiModel: true
  protocolVersions:
  - grpc-v1
  replicas: 1
  supportedModelFormats:
  - autoSelect: true
    name: openvino_ir
    version: opset1
  - autoSelect: true
    name: onnx
    version: "1"
  - autoSelect: true
    name: tensorflow
    version: "2"
  tolerations: []
  volumes:
  - emptyDir:
      medium: Memory
      sizeLimit: 2Gi
    name: shm
